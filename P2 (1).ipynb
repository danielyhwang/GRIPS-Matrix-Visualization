{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c27a6a-2c5e-46d5-8933-5233cb95515d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyscipopt in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (5.5.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (1.15.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (from pyscipopt) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sonali prajapati\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyscipopt networkx scipy pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad3521d-ffe0-4ba6-9921-416b642eb981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Property</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shape</td>\n",
       "      <td>(27, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparsity (%)</td>\n",
       "      <td>34.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Row NNZ Variance</td>\n",
       "      <td>49.02332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Column NNZ Variance</td>\n",
       "      <td>32.595556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Min coefficient</td>\n",
       "      <td>-13.584217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Max coefficient</td>\n",
       "      <td>1.706934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mean coefficient</td>\n",
       "      <td>-2.749368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Std coefficient</td>\n",
       "      <td>3.554946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Integer-like (%)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Largest abs coefficient</td>\n",
       "      <td>13.584217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Avg Row max/min ratio</td>\n",
       "      <td>13.494934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Condition number</td>\n",
       "      <td>174.390949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Matrix rank</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Diag Dominant Rows (%)</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Avg row L2 norm</td>\n",
       "      <td>12.895752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Max row L2 norm</td>\n",
       "      <td>60.167667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Zero rows</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Zero columns</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Avg degree</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Max degree</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Clustering Coef (avg)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Connected components</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Property       Value\n",
       "0                     Shape    (27, 30)\n",
       "1              Sparsity (%)   34.320988\n",
       "2          Row NNZ Variance    49.02332\n",
       "3       Column NNZ Variance   32.595556\n",
       "4           Min coefficient  -13.584217\n",
       "5           Max coefficient    1.706934\n",
       "6          Mean coefficient   -2.749368\n",
       "7           Std coefficient    3.554946\n",
       "8          Integer-like (%)         0.0\n",
       "9   Largest abs coefficient   13.584217\n",
       "10    Avg Row max/min ratio   13.494934\n",
       "11         Condition number  174.390949\n",
       "12              Matrix rank          27\n",
       "13   Diag Dominant Rows (%)         N/A\n",
       "14          Avg row L2 norm   12.895752\n",
       "15          Max row L2 norm   60.167667\n",
       "16                Zero rows           0\n",
       "17             Zero columns           0\n",
       "18               Avg degree        29.0\n",
       "19               Max degree          29\n",
       "20    Clustering Coef (avg)         1.0\n",
       "21     Connected components           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyscipopt import Model\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.linalg import svd\n",
    "from numpy.linalg import matrix_rank\n",
    "import networkx as nx\n",
    "\n",
    "# STEP 2: Load your MPS model\n",
    "model = Model()\n",
    "model.readProblem(\"gen-ip054.mps\")  # Make sure the file is in the same directory\n",
    "\n",
    "# STEP 3: Extract matrix A, RHS b, constraint senses\n",
    "variables = model.getVars()\n",
    "constraints = model.getConss()\n",
    "var_names = [v.name for v in variables]\n",
    "var_index = {name: idx for idx, name in enumerate(var_names)}\n",
    "n_vars = len(variables)\n",
    "n_cons = len(constraints)\n",
    "\n",
    "A = np.zeros((n_cons, n_vars))\n",
    "b = []\n",
    "senses = []\n",
    "\n",
    "for i, cons in enumerate(constraints):\n",
    "    terms = model.getValsLinear(cons)\n",
    "    for var_name in terms:\n",
    "        j = var_index[var_name]\n",
    "        A[i, j] = terms[var_name]\n",
    "    lhs, rhs = model.getLhs(cons), model.getRhs(cons)\n",
    "    if lhs == rhs:\n",
    "        senses.append(\"=\")\n",
    "        b.append(rhs)\n",
    "    elif np.isfinite(rhs):\n",
    "        senses.append(\"<=\")\n",
    "        b.append(rhs)\n",
    "    else:\n",
    "        senses.append(\">=\")\n",
    "        b.append(lhs)\n",
    "\n",
    "# STEP 4: Convert A to sparse and get non-zero entries\n",
    "A_sparse = csr_matrix(A)\n",
    "A_dense = A\n",
    "nonzeros = A_sparse.data\n",
    "\n",
    "# STEP 5: Compute properties (structured from PDF)\n",
    "summary = {}\n",
    "\n",
    "# 1. Sparsity Metrics\n",
    "summary[\"Shape\"] = A.shape\n",
    "summary[\"Sparsity (%)\"] = 100 * (1 - A_sparse.nnz / (A.shape[0] * A.shape[1]))\n",
    "summary[\"Row NNZ Variance\"] = np.var(np.diff(A_sparse.indptr))\n",
    "summary[\"Column NNZ Variance\"] = np.var(np.diff(csr_matrix(A_sparse.T).indptr))\n",
    "\n",
    "# 2. Coefficient Scale\n",
    "summary[\"Min coefficient\"] = np.min(nonzeros)\n",
    "summary[\"Max coefficient\"] = np.max(nonzeros)\n",
    "summary[\"Mean coefficient\"] = np.mean(nonzeros)\n",
    "summary[\"Std coefficient\"] = np.std(nonzeros)\n",
    "summary[\"Integer-like (%)\"] = 100 * np.sum(np.isclose(nonzeros % 1, 0, atol=1e-6)) / len(nonzeros)\n",
    "summary[\"Largest abs coefficient\"] = np.max(np.abs(nonzeros))\n",
    "summary[\"Avg Row max/min ratio\"] = np.mean([\n",
    "    np.max(row[row != 0]) / np.min(np.abs(row[row != 0])) if np.any(row != 0) and np.min(np.abs(row[row != 0])) > 0 else 0\n",
    "    for row in A_dense\n",
    "])\n",
    "\n",
    "# 3. Conditioning\n",
    "U, s, Vt = svd(A_dense, full_matrices=False)\n",
    "summary[\"Condition number\"] = s[0] / s[-1] if s[-1] != 0 else np.inf\n",
    "summary[\"Matrix rank\"] = matrix_rank(A_dense)\n",
    "\n",
    "# 4. Diagonal dominance (only if square)\n",
    "if A.shape[0] == A.shape[1]:\n",
    "    diag = np.abs(np.diag(A_dense))\n",
    "    off_diag_sum = np.sum(np.abs(A_dense), axis=1) - diag\n",
    "    summary[\"Diag Dominant Rows (%)\"] = 100 * np.sum(diag > off_diag_sum) / A.shape[0]\n",
    "else:\n",
    "    summary[\"Diag Dominant Rows (%)\"] = \"N/A\"\n",
    "\n",
    "# 6. Norms\n",
    "row_l2_norms = np.linalg.norm(A_dense, axis=1)\n",
    "summary[\"Avg row L2 norm\"] = np.mean(row_l2_norms)\n",
    "summary[\"Max row L2 norm\"] = np.max(row_l2_norms)\n",
    "summary[\"Zero rows\"] = np.sum(np.all(A_dense == 0, axis=1))\n",
    "summary[\"Zero columns\"] = np.sum(np.all(A_dense == 0, axis=0))\n",
    "\n",
    "# 8. Graph metrics\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(A.shape[1]))\n",
    "for i in range(A.shape[0]):\n",
    "    cols = list(A_sparse.getrow(i).nonzero()[1])\n",
    "    for j in range(len(cols)):\n",
    "        for k in range(j + 1, len(cols)):\n",
    "            G.add_edge(cols[j], cols[k])\n",
    "\n",
    "degrees = [d for _, d in G.degree()]\n",
    "summary[\"Avg degree\"] = np.mean(degrees)\n",
    "summary[\"Max degree\"] = np.max(degrees)\n",
    "summary[\"Clustering Coef (avg)\"] = np.mean(list(nx.clustering(G).values()))\n",
    "summary[\"Connected components\"] = nx.number_connected_components(G)\n",
    "\n",
    "# STEP 6: Display the summary\n",
    "df_summary = pd.DataFrame(summary.items(), columns=[\"Property\", \"Value\"])\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7eadb-2a77-460b-a435-2a25e5fd704e",
   "metadata": {},
   "source": [
    "##  Load MPS File and Extract Matrix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c858a2-7646-4bee-a781-0a77995fd80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Matrix A shape: (27, 30)\n",
      "Number of constraints: 27\n",
      "Number of variables: 30\n"
     ]
    }
   ],
   "source": [
    "# Load PySCIPOpt and extract matrix A\n",
    "from pyscipopt import Model\n",
    "import numpy as np\n",
    "\n",
    "model = Model()\n",
    "model.readProblem(\"gen-ip054.mps\")\n",
    "\n",
    "variables = model.getVars()\n",
    "constraints = model.getConss()\n",
    "\n",
    "var_names = [v.name for v in variables]\n",
    "var_index = {name: idx for idx, name in enumerate(var_names)}\n",
    "\n",
    "A = np.zeros((len(constraints), len(variables)))\n",
    "b = []\n",
    "senses = []\n",
    "\n",
    "for i, cons in enumerate(constraints):\n",
    "    terms = model.getValsLinear(cons)\n",
    "    for var_name in terms:\n",
    "        j = var_index[var_name]\n",
    "        A[i, j] = terms[var_name]\n",
    "    lhs, rhs = model.getLhs(cons), model.getRhs(cons)\n",
    "    if lhs == rhs:\n",
    "        senses.append(\"=\")\n",
    "        b.append(rhs)\n",
    "    elif np.isfinite(rhs):\n",
    "        senses.append(\"<=\")\n",
    "        b.append(rhs)\n",
    "    else:\n",
    "        senses.append(\">=\")\n",
    "        b.append(lhs)\n",
    "\n",
    "print(f\"âœ… Matrix A shape: {A.shape}\")\n",
    "print(f\"Number of constraints: {len(constraints)}\")\n",
    "print(f\"Number of variables: {len(variables)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913ac9d7-633a-429e-8ecb-e0fea0f37e42",
   "metadata": {},
   "source": [
    "## Sparsity & Nonzero Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8aa2fc4-b488-4320-85ec-51941feb9a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Sparsity Analysis:\n",
      " - Total entries: 810\n",
      " - Non-zero entries: 532\n",
      " - Sparsity: 34.32%\n",
      "ðŸ“ Bandwidth Analysis:\n",
      " - Matrix bandwidth: 28\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "A_sparse = csr_matrix(A)\n",
    "\n",
    "total_entries = A.shape[0] * A.shape[1]\n",
    "nnz = A_sparse.nnz\n",
    "sparsity_percent = 100 * (1 - nnz / total_entries)\n",
    "\n",
    "print(\"ðŸ” Sparsity Analysis:\")\n",
    "print(f\" - Total entries: {total_entries}\")\n",
    "print(f\" - Non-zero entries: {nnz}\")\n",
    "print(f\" - Sparsity: {sparsity_percent:.2f}%\")\n",
    "\n",
    "# Compute bandwidth: max(|i - j|) for all A[i, j] â‰  0\n",
    "row_indices, col_indices = A_sparse.nonzero()\n",
    "bandwidth = np.max(np.abs(row_indices - col_indices))\n",
    "\n",
    "print(\"ðŸ“ Bandwidth Analysis:\")\n",
    "print(f\" - Matrix bandwidth: {bandwidth}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5991a66a-5e03-47fd-a21a-fab7b04abcc1",
   "metadata": {},
   "source": [
    "## Coefficient Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb688a4-d717-4b3b-b63f-ddf9c24f8cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¢ Coefficient Stats:\n",
      " - Min coefficient: -13.5842166\n",
      " - Max coefficient: 1.706933862\n",
      " - Mean coefficient: -2.7494\n",
      " - Std deviation: 3.5549\n",
      " - Largest abs coefficient: 13.5842166\n"
     ]
    }
   ],
   "source": [
    "nonzeros = A_sparse.data\n",
    "\n",
    "print(\"ðŸ”¢ Coefficient Stats:\")\n",
    "print(f\" - Min coefficient: {np.min(nonzeros)}\")\n",
    "print(f\" - Max coefficient: {np.max(nonzeros)}\")\n",
    "print(f\" - Mean coefficient: {np.mean(nonzeros):.4f}\")\n",
    "print(f\" - Std deviation: {np.std(nonzeros):.4f}\")\n",
    "print(f\" - Largest abs coefficient: {np.max(np.abs(nonzeros))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ad60a-f2f0-4160-8964-0c261fb240d5",
   "metadata": {},
   "source": [
    "##  Integer-Like Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6df79a8-e728-424f-bb08-2672c97ba8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¢ Integer Check:\n",
      " - Integer-like values: 0\n",
      " - Integer-like ratio: 0.00%\n"
     ]
    }
   ],
   "source": [
    "int_like_count = np.sum(np.isclose(nonzeros % 1, 0, atol=1e-6))\n",
    "int_ratio = 100 * int_like_count / len(nonzeros)\n",
    "\n",
    "print(\"ðŸ”¢ Integer Check:\")\n",
    "print(f\" - Integer-like values: {int_like_count}\")\n",
    "print(f\" - Integer-like ratio: {int_ratio:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cfef93-0558-4674-b9b4-658c8e0315c8",
   "metadata": {},
   "source": [
    "## Row Scaling â€“ Max/Min Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60cb1563-a5c8-4a6a-9416-bf58629d5d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Row Scaling Ratios:\n",
      " - Avg max/min ratio: 26.89\n",
      " - Max max/min ratio: 179.02\n"
     ]
    }
   ],
   "source": [
    "row_ratios = []\n",
    "for row in A:\n",
    "    nz = row[row != 0]\n",
    "    if len(nz) > 1 and np.min(np.abs(nz)) > 0:\n",
    "        row_ratios.append(np.max(np.abs(nz)) / np.min(np.abs(nz)))\n",
    "\n",
    "print(\"ðŸ“ Row Scaling Ratios:\")\n",
    "print(f\" - Avg max/min ratio: {np.mean(row_ratios):.2f}\")\n",
    "print(f\" - Max max/min ratio: {np.max(row_ratios):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d853b24-fc26-4b4a-b1db-2b82b81af029",
   "metadata": {},
   "source": [
    "##  Matrix Rank and Condition Number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f702dd-101b-44c6-9c07-8a6920199f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¬ Linear Algebra:\n",
      " - Matrix rank: 27\n",
      " - Condition number: 1.74e+02\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import svd\n",
    "from numpy.linalg import matrix_rank\n",
    "\n",
    "U, s, Vt = svd(A, full_matrices=False)\n",
    "cond_number = s[0] / s[-1] if s[-1] != 0 else np.inf\n",
    "rank_val = matrix_rank(A)\n",
    "\n",
    "print(\"ðŸ”¬ Linear Algebra:\")\n",
    "print(f\" - Matrix rank: {rank_val}\")\n",
    "print(f\" - Condition number: {cond_number:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a87cc86-92e7-4053-b7a2-b43803b6f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "#Rank shows if constraints are redundant.\n",
    "#Condition number tells how numerically stable the matrix is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9918456-2f59-459e-bf78-5bdc7038444a",
   "metadata": {},
   "source": [
    "## Norms and Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c687291-4ea2-4127-a469-27295be03139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Norms & Zeros:\n",
      " - Avg row L2 norm: 12.90\n",
      " - Max row L2 norm: 60.17\n",
      " - Zero rows: 0\n",
      " - Zero columns: 0\n"
     ]
    }
   ],
   "source": [
    "l2_norms = np.linalg.norm(A, axis=1)\n",
    "zero_rows = np.sum(np.all(A == 0, axis=1))\n",
    "zero_cols = np.sum(np.all(A == 0, axis=0))\n",
    "\n",
    "print(\"ðŸ“ Norms & Zeros:\")\n",
    "print(f\" - Avg row L2 norm: {np.mean(l2_norms):.2f}\")\n",
    "print(f\" - Max row L2 norm: {np.max(l2_norms):.2f}\")\n",
    "print(f\" - Zero rows: {zero_rows}\")\n",
    "print(f\" - Zero columns: {zero_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c4a8f7-e16c-415c-bd09-3c2b22c93f64",
   "metadata": {},
   "source": [
    "## Build Variable Interaction Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a028b3-cb7b-4623-90e0-2ae639fb7652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Graph built from constraint matrix\n",
      " - Total variables (nodes): 30\n",
      " - Total interactions (edges): 435\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create an undirected graph\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(A.shape[1]))  # one node per variable\n",
    "\n",
    "# Add edges for co-occurring variables in each constraint\n",
    "for i in range(A.shape[0]):\n",
    "    cols = list(A_sparse.getrow(i).nonzero()[1])\n",
    "    for j in range(len(cols)):\n",
    "        for k in range(j + 1, len(cols)):\n",
    "            G.add_edge(cols[j], cols[k])\n",
    "\n",
    "print(\"âœ… Graph built from constraint matrix\")\n",
    "print(f\" - Total variables (nodes): {G.number_of_nodes()}\")\n",
    "print(f\" - Total interactions (edges): {G.number_of_edges()}\")\n",
    "\n",
    "#This graph models variable-variable interactions, which lets us apply graph theory:\n",
    "#Higher connectivity may mean denser subproblems\n",
    "#Sparsity can help decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fd112-3949-4731-870c-8e6b1a57c954",
   "metadata": {},
   "source": [
    "## Analyze Graph Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c6e3968-719d-4cb2-be38-9613ea3daa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Graph Metrics:\n",
      " - Average node degree: 29.00\n",
      " - Maximum node degree: 29\n",
      " - Average clustering coefficient: 1.0000\n",
      " - Number of connected components: 1\n"
     ]
    }
   ],
   "source": [
    "# Degree stats\n",
    "degrees = [d for _, d in G.degree()]\n",
    "avg_degree = np.mean(degrees)\n",
    "max_degree = np.max(degrees)\n",
    "\n",
    "# Clustering and connectivity\n",
    "clustering_coeff = nx.average_clustering(G)\n",
    "connected_components = nx.number_connected_components(G)\n",
    "\n",
    "print(\"ðŸ“Š Graph Metrics:\")\n",
    "print(f\" - Average node degree: {avg_degree:.2f}\")\n",
    "print(f\" - Maximum node degree: {max_degree}\")\n",
    "print(f\" - Average clustering coefficient: {clustering_coeff:.4f}\")\n",
    "print(f\" - Number of connected components: {connected_components}\")\n",
    "\n",
    "#Degree\t                 : How many constraints involve each variable\n",
    "#Clustering\tLocal density: are groups of variables tightly coupled?\n",
    "#Connected components\t : Disconnected blocks = potential decomposable submodels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca5069f-f623-4f39-be42-2f45220c9654",
   "metadata": {},
   "source": [
    "## Visualize (small graph only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91355983-9df6-42b1-9f2a-87b2bbec2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Draw subgraph for first 50 variables\n",
    "nodes_subset = list(G.nodes)[:50]\n",
    "subG = G.subgraph(nodes_subset)\n",
    "\n",
    "#plt.figure(figsize=(8, 6))\n",
    "#nx.draw(subG, with_labels=True, node_size=300, node_color='skyblue', font_size=8)\n",
    "#plt.title(\"ðŸ”— Variable Interaction Subgraph (first 50 variables)\")\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f69f8-a0de-4786-81d1-040956dab083",
   "metadata": {},
   "source": [
    "## Short Summarey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3653c92-a1e3-4103-be20-6108ccf91fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd32a59c-1729-4de2-9918-4ac5e53a7af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose df_summary holds your summary\n",
    "df_summary = pd.DataFrame([\n",
    "    [\"Shape\", A.shape],\n",
    "    [\"Sparsity (%)\", sparsity_percent],\n",
    "    [\"Non-zero entries\", A_sparse.nnz],\n",
    "    [\"Min coefficient\", np.min(nonzeros)],\n",
    "    [\"Max coefficient\", np.max(nonzeros)],\n",
    "    [\"Integer-like (%)\", int_ratio],\n",
    "    [\"Condition number\", cond_number],\n",
    "    [\"Matrix rank\", rank_val],\n",
    "    [\"Avg row L2 norm\", np.mean(l2_norms)],\n",
    "    [\"Zero rows\", zero_rows],\n",
    "    [\"Zero columns\", zero_cols],\n",
    "    [\"Avg degree\", avg_degree],\n",
    "    [\"Clustering Coefficient\", clustering_coeff],\n",
    "    [\"Connected components\", connected_components]\n",
    "], columns=[\"Property\", \"Value\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cef6ee-3dfe-454f-bf66-517c8a15d0de",
   "metadata": {},
   "source": [
    "## 1. Sparsity-Related Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "583f5de0-3eee-4e63-8733-316168f784df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”· 1. Sparsity-Related Metrics\n",
      "\n",
      "ðŸ“ Matrix shape: 27 rows x 30 columns\n",
      "ðŸ”¹ Total entries: 810\n",
      "ðŸ”¹ Non-zero entries: 532\n",
      "ðŸ”¹ Sparsity: 34.32%\n",
      "ðŸ§  Explanation: Sparsity is the % of zero entries in the matrix A. High sparsity is common in optimization problems.\n",
      "\n",
      "ðŸ”¸ Average non-zero entries per row: 19.70\n",
      "ðŸ”¸ Average non-zero entries per column: 17.73\n",
      "ðŸ§  Explanation: These counts show how dense each row/column is, which affects solver effort.\n",
      "\n",
      "ðŸ”¸ Variance of non-zero entries across rows: 49.02\n",
      "ðŸ”¸ Variance of non-zero entries across columns: 32.60\n",
      "ðŸ§  Explanation: High variance means some rows/columns are much denser than others â€” this can cause imbalance in the solver's workload.\n",
      "\n",
      "ðŸ”¸ Matrix Bandwidth: 28\n",
      "ðŸ§  Explanation: Bandwidth measures how far non-zero entries lie from the diagonal. Lower bandwidth = better for solver reordering.\n",
      "\n",
      "âœ… All Sparsity-Related Metrics Computed.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Required imports\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# ðŸ§® Convert matrix A to sparse format (assuming you already loaded A)\n",
    "A_sparse = csr_matrix(A)\n",
    "\n",
    "# ðŸ”¹ Step 1: Sparsity (% of zero entries)\n",
    "total_entries = A_sparse.shape[0] * A_sparse.shape[1]\n",
    "non_zero_entries = A_sparse.nnz\n",
    "sparsity = 100 * (1 - non_zero_entries / total_entries)\n",
    "\n",
    "print(\"ðŸ”· 1. Sparsity-Related Metrics\\n\")\n",
    "print(f\"ðŸ“ Matrix shape: {A_sparse.shape[0]} rows x {A_sparse.shape[1]} columns\")\n",
    "print(f\"ðŸ”¹ Total entries: {total_entries}\")\n",
    "print(f\"ðŸ”¹ Non-zero entries: {non_zero_entries}\")\n",
    "print(f\"ðŸ”¹ Sparsity: {sparsity:.2f}%\")\n",
    "print(\"ðŸ§  Explanation: Sparsity is the % of zero entries in the matrix A. High sparsity is common in optimization problems.\\n\")\n",
    "\n",
    "# ðŸ”¹ Step 2: Row/Column Nonzero Counts\n",
    "row_nnz = np.diff(A_sparse.indptr)\n",
    "col_nnz = np.diff(csr_matrix(A_sparse.T).indptr)\n",
    "\n",
    "print(f\"ðŸ”¸ Average non-zero entries per row: {np.mean(row_nnz):.2f}\")\n",
    "print(f\"ðŸ”¸ Average non-zero entries per column: {np.mean(col_nnz):.2f}\")\n",
    "print(\"ðŸ§  Explanation: These counts show how dense each row/column is, which affects solver effort.\\n\")\n",
    "\n",
    "# ðŸ”¹ Step 3: Row/Column Density Variance\n",
    "row_var = np.var(row_nnz)\n",
    "col_var = np.var(col_nnz)\n",
    "\n",
    "print(f\"ðŸ”¸ Variance of non-zero entries across rows: {row_var:.2f}\")\n",
    "print(f\"ðŸ”¸ Variance of non-zero entries across columns: {col_var:.2f}\")\n",
    "print(\"ðŸ§  Explanation: High variance means some rows/columns are much denser than others â€” this can cause imbalance in the solver's workload.\\n\")\n",
    "\n",
    "# ðŸ”¹ Step 4: Bandwidth\n",
    "row_indices, col_indices = A_sparse.nonzero()\n",
    "bandwidth = np.max(np.abs(row_indices - col_indices))\n",
    "\n",
    "print(f\"ðŸ”¸ Matrix Bandwidth: {bandwidth}\")\n",
    "print(\"ðŸ§  Explanation: Bandwidth measures how far non-zero entries lie from the diagonal. Lower bandwidth = better for solver reordering.\\n\")\n",
    "\n",
    "print(\"âœ… All Sparsity-Related Metrics Computed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2df3ee-341f-4b20-a7ac-f66d37cdf854",
   "metadata": {},
   "source": [
    "##  2. Coefficient Size & Scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8933941-a031-4698-8763-e392cd3bef08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”· 2. Coefficient Size & Scale Metrics\n",
      "\n",
      "ðŸ“Š Total non-zero coefficients: 532\n",
      "ðŸ”¹ Min value: -13.5842166\n",
      "ðŸ”¹ Max value: 1.706933862\n",
      "ðŸ”¹ Mean value: -2.7494\n",
      "ðŸ”¹ Standard deviation: 3.5549\n",
      "ðŸ§  Explanation: These describe the spread of coefficients in A. Large values or big variance may slow solver performance.\n",
      "\n",
      "ðŸ”¹ Avg row-wise max/min ratio: 26.89\n",
      "ðŸ”¹ Max row-wise max/min ratio: 179.02\n",
      "ðŸ§  Explanation: This highlights scaling issues â€” rows with large ratio can cause numerical instability.\n",
      "\n",
      "ðŸ”¹ Largest absolute coefficient: 13.5842166\n",
      "ðŸ§  Explanation: Large absolute values affect solver tolerances. Try normalizing if this is very high.\n",
      "\n",
      "ðŸ”¹ Integer-like coefficients: 0 (0.00%)\n",
      "ðŸ”¹ Fractional coefficients: 532 (100.00%)\n",
      "ðŸ§  Explanation: Pure IP models often use integer coefficients. Fractional values suggest a scaled or mixed-integer model.\n",
      "\n",
      "âœ… Coefficient Size & Scale Metrics Computed.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Required imports\n",
    "import numpy as np\n",
    "\n",
    "# ðŸ”¹ Ensure youâ€™re working with sparse matrix\n",
    "nonzeros = A_sparse.data\n",
    "\n",
    "print(\"ðŸ”· 2. Coefficient Size & Scale Metrics\\n\")\n",
    "\n",
    "# ðŸ”¸ 1. Basic Stats\n",
    "print(f\"ðŸ“Š Total non-zero coefficients: {len(nonzeros)}\")\n",
    "print(f\"ðŸ”¹ Min value: {np.min(nonzeros)}\")\n",
    "print(f\"ðŸ”¹ Max value: {np.max(nonzeros)}\")\n",
    "print(f\"ðŸ”¹ Mean value: {np.mean(nonzeros):.4f}\")\n",
    "print(f\"ðŸ”¹ Standard deviation: {np.std(nonzeros):.4f}\")\n",
    "print(\"ðŸ§  Explanation: These describe the spread of coefficients in A. Large values or big variance may slow solver performance.\\n\")\n",
    "\n",
    "# ðŸ”¸ 2. Row-wise max/min ratio (scaling)\n",
    "row_ratios = []\n",
    "for row in A:\n",
    "    nz = row[row != 0]\n",
    "    if len(nz) > 1 and np.min(np.abs(nz)) > 0:\n",
    "        row_ratios.append(np.max(np.abs(nz)) / np.min(np.abs(nz)))\n",
    "\n",
    "print(f\"ðŸ”¹ Avg row-wise max/min ratio: {np.mean(row_ratios):.2f}\")\n",
    "print(f\"ðŸ”¹ Max row-wise max/min ratio: {np.max(row_ratios):.2f}\")\n",
    "print(\"ðŸ§  Explanation: This highlights scaling issues â€” rows with large ratio can cause numerical instability.\\n\")\n",
    "\n",
    "# ðŸ”¸ 3. Largest absolute coefficient\n",
    "print(f\"ðŸ”¹ Largest absolute coefficient: {np.max(np.abs(nonzeros))}\")\n",
    "print(\"ðŸ§  Explanation: Large absolute values affect solver tolerances. Try normalizing if this is very high.\\n\")\n",
    "\n",
    "# ðŸ”¸ 4. Fraction of integer vs fractional coefficients\n",
    "integer_like = np.sum(np.isclose(nonzeros % 1, 0, atol=1e-6))\n",
    "fractional = len(nonzeros) - integer_like\n",
    "integer_ratio = 100 * integer_like / len(nonzeros)\n",
    "\n",
    "print(f\"ðŸ”¹ Integer-like coefficients: {integer_like} ({integer_ratio:.2f}%)\")\n",
    "print(f\"ðŸ”¹ Fractional coefficients: {fractional} ({100 - integer_ratio:.2f}%)\")\n",
    "print(\"ðŸ§  Explanation: Pure IP models often use integer coefficients. Fractional values suggest a scaled or mixed-integer model.\\n\")\n",
    "\n",
    "print(\"âœ… Coefficient Size & Scale Metrics Computed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dbc896-474e-4f98-a864-b12699d4455e",
   "metadata": {},
   "source": [
    "## 3. Condition-Related "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e582dad8-70f6-404e-8571-e9558648de76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”· 3. Condition-Related Metrics\n",
      "\n",
      "ðŸ”¹ Condition Number: 1.74e+02\n",
      "ðŸ§  Explanation: The condition number is the ratio of the largest to smallest singular values.\n",
      "   A large number (e.g. >1e5) suggests ill-conditioning â†’ may cause instability for solvers.\n",
      "\n",
      "ðŸ”¹ Matrix Rank: 27\n",
      "ðŸ§  Explanation: Rank indicates linear independence. If rank < number of rows, the system is redundant or overconstrained.\n",
      "\n",
      "âš ï¸ Diagonal dominance not computed (matrix is not square).\n",
      "ðŸ§  Explanation: Diagonal dominance only applies to square matrices (same # constraints as variables).\n",
      "\n",
      "âœ… Condition-Related Metrics Computed.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Required imports\n",
    "from scipy.linalg import svd\n",
    "from numpy.linalg import matrix_rank\n",
    "\n",
    "print(\"ðŸ”· 3. Condition-Related Metrics\\n\")\n",
    "\n",
    "# ðŸ”¸ 1. Condition Number (via SVD)\n",
    "U, s, Vt = svd(A, full_matrices=False)\n",
    "cond_number = s[0] / s[-1] if s[-1] > 0 else np.inf\n",
    "\n",
    "print(f\"ðŸ”¹ Condition Number: {cond_number:.2e}\")\n",
    "print(\"ðŸ§  Explanation: The condition number is the ratio of the largest to smallest singular values.\")\n",
    "print(\"   A large number (e.g. >1e5) suggests ill-conditioning â†’ may cause instability for solvers.\\n\")\n",
    "\n",
    "# ðŸ”¸ 2. Matrix Rank\n",
    "rank_val = matrix_rank(A)\n",
    "print(f\"ðŸ”¹ Matrix Rank: {rank_val}\")\n",
    "print(\"ðŸ§  Explanation: Rank indicates linear independence. If rank < number of rows, the system is redundant or overconstrained.\\n\")\n",
    "\n",
    "# ðŸ”¸ 3. Diagonal Dominance (only applies if square matrix)\n",
    "if A.shape[0] == A.shape[1]:\n",
    "    diag = np.abs(np.diag(A))\n",
    "    off_diag_sum = np.sum(np.abs(A), axis=1) - diag\n",
    "    diag_dominant_rows = np.sum(diag > off_diag_sum)\n",
    "    dominance_percent = 100 * diag_dominant_rows / A.shape[0]\n",
    "\n",
    "    print(f\"ðŸ”¹ Diagonally Dominant Rows: {diag_dominant_rows} ({dominance_percent:.2f}%)\")\n",
    "    print(\"ðŸ§  Explanation: A row is diagonally dominant if its diagonal entry is larger than the sum of all other entries.\")\n",
    "    print(\"   This improves numerical stability. Often checked in linear system solvers.\\n\")\n",
    "else:\n",
    "    print(\"âš ï¸ Diagonal dominance not computed (matrix is not square).\")\n",
    "    print(\"ðŸ§  Explanation: Diagonal dominance only applies to square matrices (same # constraints as variables).\\n\")\n",
    "\n",
    "print(\"âœ… Condition-Related Metrics Computed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5810c-7205-4c5e-927a-f0f2841344d1",
   "metadata": {},
   "source": [
    "## 4. Structural Graph-Theoretic Metrics (via networkx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dbcd1f3-369f-4f3a-8946-9236b183e8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”· 4. Structural Graph-Theoretic Metrics\n",
      "\n",
      "ðŸ“¦ Graph built with 30 variables (nodes) and 435 edges (co-occurrence links)\n",
      "\n",
      "ðŸ”¹ Average node degree: 29.00\n",
      "ðŸ”¹ Maximum node degree: 29\n",
      "ðŸ§  Explanation: High-degree nodes are involved in many constraints â€” they are bottlenecks or hubs.\n",
      "\n",
      "ðŸ”¹ Average clustering coefficient: 1.0000\n",
      "ðŸ§  Explanation: Measures how connected a node's neighbors are. High values = dense variable neighborhoods.\n",
      "\n",
      "ðŸ”¹ Number of connected components: 1\n",
      "ðŸ”¹ Largest component size: 30\n",
      "ðŸ§  Explanation: Disconnected subgraphs can be optimized independently â€” useful for decomposition.\n",
      "\n",
      "ðŸ”¹ Treewidth (approximate): 29\n",
      "ðŸ§  Explanation: Low treewidth â†’ better solver performance due to decomposability.\n",
      "\n",
      "âœ… Structural Graph-Theoretic Metrics Computed.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Required imports\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"ðŸ”· 4. Structural Graph-Theoretic Metrics\\n\")\n",
    "\n",
    "# ðŸ”¸ Step 1: Build Variable Interaction Graph\n",
    "# Each node = variable (column); edges = co-occurrence in a constraint (row)\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(A.shape[1]))\n",
    "\n",
    "for i in range(A.shape[0]):\n",
    "    cols = list(A_sparse.getrow(i).nonzero()[1])\n",
    "    for j in range(len(cols)):\n",
    "        for k in range(j + 1, len(cols)):\n",
    "            G.add_edge(cols[j], cols[k])\n",
    "\n",
    "print(f\"ðŸ“¦ Graph built with {G.number_of_nodes()} variables (nodes) and {G.number_of_edges()} edges (co-occurrence links)\\n\")\n",
    "\n",
    "# ðŸ”¸ Step 2: Degree Distribution\n",
    "degrees = [deg for _, deg in G.degree()]\n",
    "avg_degree = np.mean(degrees)\n",
    "max_degree = np.max(degrees)\n",
    "\n",
    "print(f\"ðŸ”¹ Average node degree: {avg_degree:.2f}\")\n",
    "print(f\"ðŸ”¹ Maximum node degree: {max_degree}\")\n",
    "print(\"ðŸ§  Explanation: High-degree nodes are involved in many constraints â€” they are bottlenecks or hubs.\\n\")\n",
    "\n",
    "# ðŸ”¸ Step 3: Clustering Coefficient\n",
    "clustering = nx.clustering(G)\n",
    "clustering_avg = np.mean(list(clustering.values()))\n",
    "\n",
    "print(f\"ðŸ”¹ Average clustering coefficient: {clustering_avg:.4f}\")\n",
    "print(\"ðŸ§  Explanation: Measures how connected a node's neighbors are. High values = dense variable neighborhoods.\\n\")\n",
    "\n",
    "# ðŸ”¸ Step 4: Connected Components\n",
    "components = list(nx.connected_components(G))\n",
    "num_components = len(components)\n",
    "component_sizes = [len(c) for c in components]\n",
    "largest_component = max(component_sizes)\n",
    "\n",
    "print(f\"ðŸ”¹ Number of connected components: {num_components}\")\n",
    "print(f\"ðŸ”¹ Largest component size: {largest_component}\")\n",
    "print(\"ðŸ§  Explanation: Disconnected subgraphs can be optimized independently â€” useful for decomposition.\\n\")\n",
    "\n",
    "# ðŸ”¸ Step 5 (Optional): Treewidth (heuristic via min fill-in)\n",
    "try:\n",
    "    from networkx.algorithms.approximation.treewidth import treewidth_min_fill_in\n",
    "    tw, _ = treewidth_min_fill_in(G)\n",
    "    print(f\"ðŸ”¹ Treewidth (approximate): {tw}\")\n",
    "    print(\"ðŸ§  Explanation: Low treewidth â†’ better solver performance due to decomposability.\\n\")\n",
    "except:\n",
    "    print(\"âš ï¸ Treewidth estimation not available â€” requires `networkx >= 2.6`.\")\n",
    "    print(\"ðŸ§  Explanation: Treewidth is NP-hard to compute exactly, so approximation is used.\\n\")\n",
    "\n",
    "print(\"âœ… Structural Graph-Theoretic Metrics Computed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50f951-b0ff-4cbf-8ce5-a60546caa802",
   "metadata": {},
   "source": [
    "## 5. Constraint Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dad8fac7-2f21-4390-b369-cda501b04215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”· 5. Constraint Classification\n",
      "\n",
      "ðŸ”¹ Equalities (lhs == rhs): 0\n",
      "ðŸ”¹ Inequalities (lhs â‰  rhs): 27\n",
      "ðŸ§  Explanation: Equalities are exact constraints. Inequalities allow room on one side and often involve slacks.\n",
      "\n",
      "ðŸ”¹ Variables appearing only in bounds (not in constraints): 0\n",
      "ðŸ§  Explanation: These variables don't participate in any constraint â€” they are just bounded.\n",
      "\n",
      "ðŸ”¹ Slack-like variables (only one Â±1 entry): 0\n",
      "ðŸ§  Explanation: Slack variables are added to turn inequalities into equalities and appear exactly once with Â±1.\n",
      "\n",
      "ðŸ”¹ Redundant constraints (based on matrix rank): 0\n",
      "   - Matrix rank: 27\n",
      "   - Total constraints: 27\n",
      "ðŸ§  Explanation: Redundant constraints do not add new information and may slow down the solver.\n",
      "\n",
      "âœ… Constraint classification completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”· 5. Constraint Classification\\n\")\n",
    "\n",
    "# ðŸ”¸ 1. Equalities & Inequalities\n",
    "equalities = sum(1 for i in range(len(b)) if senses[i] == \"=\")\n",
    "inequalities = len(b) - equalities\n",
    "\n",
    "print(f\"ðŸ”¹ Equalities (lhs == rhs): {equalities}\")\n",
    "print(f\"ðŸ”¹ Inequalities (lhs â‰  rhs): {inequalities}\")\n",
    "print(\"ðŸ§  Explanation: Equalities are exact constraints. Inequalities allow room on one side and often involve slacks.\\n\")\n",
    "\n",
    "# ðŸ”¸ 2. Bounds-only variables\n",
    "used_vars = set(A_sparse.nonzero()[1])\n",
    "all_vars = set(range(A_sparse.shape[1]))\n",
    "bound_only_vars = all_vars - used_vars\n",
    "\n",
    "print(f\"ðŸ”¹ Variables appearing only in bounds (not in constraints): {len(bound_only_vars)}\")\n",
    "print(\"ðŸ§  Explanation: These variables don't participate in any constraint â€” they are just bounded.\\n\")\n",
    "\n",
    "# ðŸ”¸ 3. Slack variables: exactly one row, Â±1 coefficient\n",
    "slack_vars = 0\n",
    "for j in range(A_sparse.shape[1]):\n",
    "    col_vals = A_sparse.getcol(j).toarray().flatten()\n",
    "    nonzeros = col_vals[col_vals != 0]\n",
    "    if len(nonzeros) == 1 and np.isclose(abs(nonzeros[0]), 1.0, atol=1e-6):\n",
    "        slack_vars += 1\n",
    "\n",
    "print(f\"ðŸ”¹ Slack-like variables (only one Â±1 entry): {slack_vars}\")\n",
    "print(\"ðŸ§  Explanation: Slack variables are added to turn inequalities into equalities and appear exactly once with Â±1.\\n\")\n",
    "\n",
    "# ðŸ”¸ 4. Redundant constraints (check rank)\n",
    "from numpy.linalg import matrix_rank\n",
    "\n",
    "num_constraints = A.shape[0]\n",
    "rank_val = matrix_rank(A)\n",
    "redundant = num_constraints - rank_val\n",
    "\n",
    "print(f\"ðŸ”¹ Redundant constraints (based on matrix rank): {redundant}\")\n",
    "print(f\"   - Matrix rank: {rank_val}\")\n",
    "print(f\"   - Total constraints: {num_constraints}\")\n",
    "print(\"ðŸ§  Explanation: Redundant constraints do not add new information and may slow down the solver.\\n\")\n",
    "\n",
    "print(\"âœ… Constraint classification completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0feff-7602-46ce-bc62-62ba1dba696f",
   "metadata": {},
   "source": [
    "## 6. Normalized Coefficient Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64861f5a-6936-4361-84af-1ef613430c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”· 6. Normalized Coefficient Statistics\n",
      "\n",
      "ðŸ”¹ Avg row L2 norm: 12.90\n",
      "ðŸ”¹ Max row L2 norm: 60.17\n",
      "ðŸ”¹ Avg row L1 norm: 56.57\n",
      "ðŸ”¹ Max row L1 norm: 306.29\n",
      "ðŸ§  Explanation: L1/L2 norms help detect scaling problems across constraints.\n",
      "\n",
      "ðŸ”¹ Avg normalized coefficient range (row): 26.89\n",
      "ðŸ”¹ Max normalized coefficient range (row): 179.02\n",
      "ðŸ§  Explanation: Big ranges between smallest/largest coefficient show uneven constraint scaling.\n",
      "\n",
      "ðŸ”¹ Constraints with high total weight (> 95th percentile): 2\n",
      "ðŸ§  Explanation: Heavy constraints may dominate solver behavior â€” watch for imbalance.\n",
      "\n",
      "ðŸ”¹ Zero rows (unused constraints): 0\n",
      "ðŸ”¹ Zero columns (unused variables): 0\n",
      "ðŸ§  Explanation: Zero rows or columns can usually be removed â€” they don't affect the model.\n",
      "\n",
      "âœ… Normalized Coefficient Statistics Computed.\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”· 6. Normalized Coefficient Statistics\\n\")\n",
    "\n",
    "# ðŸ”¸ 1. Row-wise Norms\n",
    "row_l2_norms = np.linalg.norm(A, axis=1)\n",
    "row_l1_norms = np.sum(np.abs(A), axis=1)\n",
    "\n",
    "print(f\"ðŸ”¹ Avg row L2 norm: {np.mean(row_l2_norms):.2f}\")\n",
    "print(f\"ðŸ”¹ Max row L2 norm: {np.max(row_l2_norms):.2f}\")\n",
    "print(f\"ðŸ”¹ Avg row L1 norm: {np.mean(row_l1_norms):.2f}\")\n",
    "print(f\"ðŸ”¹ Max row L1 norm: {np.max(row_l1_norms):.2f}\")\n",
    "print(\"ðŸ§  Explanation: L1/L2 norms help detect scaling problems across constraints.\\n\")\n",
    "\n",
    "# ðŸ”¸ 2. Coefficient range after normalization (per row)\n",
    "normalized_ranges = []\n",
    "for row in A:\n",
    "    abs_row = np.abs(row[row != 0])\n",
    "    if len(abs_row) > 1:\n",
    "        rng = np.max(abs_row) / np.min(abs_row)\n",
    "        normalized_ranges.append(rng)\n",
    "\n",
    "print(f\"ðŸ”¹ Avg normalized coefficient range (row): {np.mean(normalized_ranges):.2f}\")\n",
    "print(f\"ðŸ”¹ Max normalized coefficient range (row): {np.max(normalized_ranges):.2f}\")\n",
    "print(\"ðŸ§  Explanation: Big ranges between smallest/largest coefficient show uneven constraint scaling.\\n\")\n",
    "\n",
    "# ðŸ”¸ 3. Heavy Constraints â€“ Sum of Absolute Values per Row\n",
    "heavy_threshold = np.percentile(row_l1_norms, 95)\n",
    "heavy_constraints = np.sum(row_l1_norms > heavy_threshold)\n",
    "\n",
    "print(f\"ðŸ”¹ Constraints with high total weight (> 95th percentile): {heavy_constraints}\")\n",
    "print(\"ðŸ§  Explanation: Heavy constraints may dominate solver behavior â€” watch for imbalance.\\n\")\n",
    "\n",
    "# ðŸ”¸ 4. Zero row/column detection\n",
    "zero_rows = np.sum(np.all(A == 0, axis=1))\n",
    "zero_cols = np.sum(np.all(A == 0, axis=0))\n",
    "\n",
    "print(f\"ðŸ”¹ Zero rows (unused constraints): {zero_rows}\")\n",
    "print(f\"ðŸ”¹ Zero columns (unused variables): {zero_cols}\")\n",
    "print(\"ðŸ§  Explanation: Zero rows or columns can usually be removed â€” they don't affect the model.\\n\")\n",
    "\n",
    "print(\"âœ… Normalized Coefficient Statistics Computed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d638f-9e0e-4154-b973-4844f46a08d9",
   "metadata": {},
   "source": [
    "## 7. Redundancy and Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5b4cc97-f2dd-4c35-ac24-f59b9ca8e82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”· 6. Normalized Coefficient Statistics\n",
      "\n",
      "ðŸ”¹ Avg row L2 norm: 12.90\n",
      "ðŸ”¹ Max row L2 norm: 60.17\n",
      "ðŸ”¹ Avg row L1 norm: 56.57\n",
      "ðŸ”¹ Max row L1 norm: 306.29\n",
      "ðŸ§  Explanation: L1/L2 norms help detect scaling problems across constraints.\n",
      "\n",
      "ðŸ”¹ Avg normalized coefficient range (row): 26.89\n",
      "ðŸ”¹ Max normalized coefficient range (row): 179.02\n",
      "ðŸ§  Explanation: Big ranges between smallest/largest coefficient show uneven constraint scaling.\n",
      "\n",
      "ðŸ”¹ Constraints with high total weight (> 95th percentile): 2\n",
      "ðŸ§  Explanation: Heavy constraints may dominate solver behavior â€” watch for imbalance.\n",
      "\n",
      "ðŸ”¹ Zero rows (unused constraints): 0\n",
      "ðŸ”¹ Zero columns (unused variables): 0\n",
      "ðŸ§  Explanation: Zero rows or columns can usually be removed â€” they don't affect the model.\n",
      "\n",
      "âœ… Normalized Coefficient Statistics Computed.\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”· 6. Normalized Coefficient Statistics\\n\")\n",
    "\n",
    "# ðŸ”¸ 1. Row-wise Norms\n",
    "row_l2_norms = np.linalg.norm(A, axis=1)\n",
    "row_l1_norms = np.sum(np.abs(A), axis=1)\n",
    "\n",
    "print(f\"ðŸ”¹ Avg row L2 norm: {np.mean(row_l2_norms):.2f}\")\n",
    "print(f\"ðŸ”¹ Max row L2 norm: {np.max(row_l2_norms):.2f}\")\n",
    "print(f\"ðŸ”¹ Avg row L1 norm: {np.mean(row_l1_norms):.2f}\")\n",
    "print(f\"ðŸ”¹ Max row L1 norm: {np.max(row_l1_norms):.2f}\")\n",
    "print(\"ðŸ§  Explanation: L1/L2 norms help detect scaling problems across constraints.\\n\")\n",
    "\n",
    "# ðŸ”¸ 2. Coefficient range after normalization (per row)\n",
    "normalized_ranges = []\n",
    "for row in A:\n",
    "    abs_row = np.abs(row[row != 0])\n",
    "    if len(abs_row) > 1:\n",
    "        rng = np.max(abs_row) / np.min(abs_row)\n",
    "        normalized_ranges.append(rng)\n",
    "\n",
    "print(f\"ðŸ”¹ Avg normalized coefficient range (row): {np.mean(normalized_ranges):.2f}\")\n",
    "print(f\"ðŸ”¹ Max normalized coefficient range (row): {np.max(normalized_ranges):.2f}\")\n",
    "print(\"ðŸ§  Explanation: Big ranges between smallest/largest coefficient show uneven constraint scaling.\\n\")\n",
    "\n",
    "# ðŸ”¸ 3. Heavy Constraints â€“ Sum of Absolute Values per Row\n",
    "heavy_threshold = np.percentile(row_l1_norms, 95)\n",
    "heavy_constraints = np.sum(row_l1_norms > heavy_threshold)\n",
    "\n",
    "print(f\"ðŸ”¹ Constraints with high total weight (> 95th percentile): {heavy_constraints}\")\n",
    "print(\"ðŸ§  Explanation: Heavy constraints may dominate solver behavior â€” watch for imbalance.\\n\")\n",
    "\n",
    "# ðŸ”¸ 4. Zero row/column detection\n",
    "zero_rows = np.sum(np.all(A == 0, axis=1))\n",
    "zero_cols = np.sum(np.all(A == 0, axis=0))\n",
    "\n",
    "print(f\"ðŸ”¹ Zero rows (unused constraints): {zero_rows}\")\n",
    "print(f\"ðŸ”¹ Zero columns (unused variables): {zero_cols}\")\n",
    "print(\"ðŸ§  Explanation: Zero rows or columns can usually be removed â€” they don't affect the model.\\n\")\n",
    "\n",
    "print(\"âœ… Normalized Coefficient Statistics Computed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036f80d-f873-478a-9c73-0e49986d0199",
   "metadata": {},
   "source": [
    "## 8. Variable Participation Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dccf2d6c-c9bb-40ab-87ef-9a29bfa2ada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”· 8. Variable Participation Statistics\n",
      "\n",
      "ðŸ”¹ Avg # constraints per variable: 17.73\n",
      "ðŸ”¹ Max # constraints per variable: 24\n",
      "ðŸ§  Explanation: Highly connected variables may become bottlenecks in decomposition.\n",
      "\n",
      "ðŸ”¹ Integer or Binary variables: 30 (100.00%)\n",
      "ðŸ§  Explanation: Mixed-integer models contain a mix of discrete and continuous variables.\n",
      "\n",
      "ðŸ”¹ Slack-like variables (1 row, Â±1): 0\n",
      "ðŸ§  Explanation: Slack variables are auxiliary variables added to reformulate constraints.\n",
      "\n",
      "âœ… Variable Participation Statistics Computed.\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”· 8. Variable Participation Statistics\\n\")\n",
    "\n",
    "# 1. Constraints per variable (column nonzero count)\n",
    "col_nnz = np.diff(csr_matrix(A_sparse.T).indptr)\n",
    "avg_participation = np.mean(col_nnz)\n",
    "max_participation = np.max(col_nnz)\n",
    "\n",
    "print(f\"ðŸ”¹ Avg # constraints per variable: {avg_participation:.2f}\")\n",
    "print(f\"ðŸ”¹ Max # constraints per variable: {max_participation}\")\n",
    "print(\"ðŸ§  Explanation: Highly connected variables may become bottlenecks in decomposition.\\n\")\n",
    "\n",
    "# 2. Binary/Integer variable density (using PySCIPOpt variable type)\n",
    "integer_vars = [v for v in variables if v.vtype() in (\"BINARY\", \"INTEGER\")]\n",
    "integer_ratio = 100 * len(integer_vars) / len(variables)\n",
    "\n",
    "print(f\"ðŸ”¹ Integer or Binary variables: {len(integer_vars)} ({integer_ratio:.2f}%)\")\n",
    "print(\"ðŸ§  Explanation: Mixed-integer models contain a mix of discrete and continuous variables.\\n\")\n",
    "\n",
    "# 4. Slack variable detection\n",
    "slack_count = 0\n",
    "for j in range(A_sparse.shape[1]):\n",
    "    col_vals = A_sparse.getcol(j).toarray().flatten()\n",
    "    nonzeros = col_vals[col_vals != 0]\n",
    "    if len(nonzeros) == 1 and np.isclose(abs(nonzeros[0]), 1.0, atol=1e-6):\n",
    "        slack_count += 1\n",
    "\n",
    "print(f\"ðŸ”¹ Slack-like variables (1 row, Â±1): {slack_count}\")\n",
    "print(\"ðŸ§  Explanation: Slack variables are auxiliary variables added to reformulate constraints.\\n\")\n",
    "\n",
    "print(\"âœ… Variable Participation Statistics Computed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff58aed-22f5-4a72-a4b1-74ded81c01cd",
   "metadata": {},
   "source": [
    "## 9. Constraint Types by Pattern \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7554009-0400-4a37-bc76-50251bd26ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”· 9. Constraint Types by Pattern\n",
      "\n",
      "ðŸ”¹ Knapsack: 0 constraints\n",
      "ðŸ”¹ Packing/Covering: 0 constraints\n",
      "ðŸ”¹ Flow Conservation: 0 constraints\n",
      "ðŸ”¹ Assignment: 0 constraints\n",
      "ðŸ”¹ Set Partitioning: 0 constraints\n",
      "\n",
      "ðŸ§  Explanation:\n",
      "- These patterns often occur in structured models (e.g. flows, assignments).\n",
      "- Recognizing them allows solvers to apply special preprocessing or decomposition.\n",
      "âœ… Constraint pattern detection complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”· 9. Constraint Types by Pattern\\n\")\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Initialize counters for each constraint type\n",
    "pattern_counts = Counter({\n",
    "    \"Knapsack\": 0,\n",
    "    \"Packing/Covering\": 0,\n",
    "    \"Flow Conservation\": 0,\n",
    "    \"Assignment\": 0,\n",
    "    \"Set Partitioning\": 0\n",
    "})\n",
    "\n",
    "# Loop over all rows in A and analyze patterns\n",
    "for i in range(A.shape[0]):\n",
    "    row = A[i]\n",
    "    nz = row[row != 0]\n",
    "    abs_vals = np.abs(nz)\n",
    "    signs = np.sign(nz)\n",
    "\n",
    "    # For set-partitioning: binary vars only, rhs = 1\n",
    "    if all(v in [0, 1] for v in abs_vals) and np.isclose(b[i], 1) and senses[i] == \"=\":\n",
    "        pattern_counts[\"Set Partitioning\"] += 1\n",
    "\n",
    "    # For assignment: only one nonzero and it's 1\n",
    "    if np.count_nonzero(row) == 1 and np.isclose(nz[0], 1):\n",
    "        pattern_counts[\"Assignment\"] += 1\n",
    "\n",
    "    # Flow conservation: exactly one +1 and one -1\n",
    "    if list(signs).count(1) == 1 and list(signs).count(-1) == 1 and len(signs) == 2:\n",
    "        pattern_counts[\"Flow Conservation\"] += 1\n",
    "\n",
    "    # Knapsack: all positive and â‰¤ 1\n",
    "    if np.all(nz > 0) and np.all(nz <= 1):\n",
    "        pattern_counts[\"Knapsack\"] += 1\n",
    "\n",
    "    # Packing/Covering: 0/1 coefficients and sense â‰¤ or â‰¥\n",
    "    if all(v in [0, 1] for v in abs_vals) and senses[i] in [\"<=\", \">=\"]:\n",
    "        pattern_counts[\"Packing/Covering\"] += 1\n",
    "\n",
    "# Print summary\n",
    "for pattern, count in pattern_counts.items():\n",
    "    print(f\"ðŸ”¹ {pattern}: {count} constraints\")\n",
    "\n",
    "print(\"\\nðŸ§  Explanation:\")\n",
    "print(\"- These patterns often occur in structured models (e.g. flows, assignments).\")\n",
    "print(\"- Recognizing them allows solvers to apply special preprocessing or decomposition.\")\n",
    "print(\"âœ… Constraint pattern detection complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1966f03f-a207-4106-a213-9ec74d94077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix_statistics(self, A_sparse):\n",
    "    import pandas as pd\n",
    "\n",
    "    rows, cols = A_sparse.shape\n",
    "    total_entries = rows * cols\n",
    "    nonzeros = A_sparse.nnz\n",
    "    sparsity = 1 - nonzeros / total_entries\n",
    "\n",
    "    row_nnz = np.asarray((A_sparse != 0).sum(axis=1)).flatten()\n",
    "    col_nnz = np.asarray((A_sparse != 0).sum(axis=0)).flatten()\n",
    "\n",
    "    row_var = np.var(row_nnz)\n",
    "    col_var = np.var(col_nnz)\n",
    "\n",
    "    row_idx, col_idx = A_sparse.nonzero()\n",
    "    bandwidth = np.max(np.abs(row_idx - col_idx)) if len(row_idx) else 0\n",
    "\n",
    "    # Integer-like values check\n",
    "    values = A_sparse.data\n",
    "    is_integer_like = np.isclose(values % 1, 0, atol=1e-6)\n",
    "    integer_ratio = np.sum(is_integer_like) / len(values)\n",
    "\n",
    "    stats = {\n",
    "        \"Sparsity (%)\": [100 * sparsity],\n",
    "        \"Avg Nonzeros per Row\": [np.mean(row_nnz)],\n",
    "        \"Avg Nonzeros per Column\": [np.mean(col_nnz)],\n",
    "        \"Row Density Variance\": [row_var],\n",
    "        \"Column Density Variance\": [col_var],\n",
    "        \"Matrix Bandwidth\": [bandwidth],\n",
    "        \"Integer-Like Coefficient %\": [100 * integer_ratio],\n",
    "        \"Total Nonzeros\": [nonzeros]\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec924a3-e2fe-49e2-aa9f-5038a7d80e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PySide6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d3976-025e-432b-b8f6-22491909f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PySide6.QtWidgets import QTableWidget, QTableWidgetItem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19f21f-23dd-498a-8699-305fc1705d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PySide6.QtWidgets import (\n",
    "    QApplication, QWidget, QVBoxLayout, QTextEdit, QFileDialog,\n",
    "    QPushButton, QTableWidget, QTableWidgetItem\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c6da3-d0be-43e2-b920-25435a737b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPSLoaderApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"MPS Loader and Sparse Matrix Viewer\")\n",
    "        self.resize(800, 600)\n",
    "\n",
    "        self.matrix_stats = None  # âœ… Add it here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b5e39-27ae-4fac-b7b9-3189b47a6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc369b-d956-475c-b0b7-b600519fa8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4e243-a837-40ba-99f7-fbfb39720405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b7db4-370f-4f9b-91fc-78c69f670c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
